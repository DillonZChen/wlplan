{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (1.5.0)\n",
      "Requirement already satisfied: wlplan in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: tqdm in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: pymdzcf==0.1.0 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from wlplan) (3.5)\n",
      "Requirement already satisfied: pddl==0.4.1 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from wlplan) (0.4.1)\n",
      "Requirement already satisfied: python-sat==1.8.dev14 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from wlplan) (1.8.dev14)\n",
      "Requirement already satisfied: lark<1.2.0,>=1.1.5 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from pddl==0.4.1->wlplan) (1.1.9)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from pddl==0.4.1->wlplan) (8.2.1)\n",
      "Requirement already satisfied: six in /home/dzc/code/work/wlplan/.venv/lib/python3.12/site-packages (from python-sat==1.8.dev14->wlplan) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy scikit-learn wlplan tqdm pymdzcf==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how you can use `wlplan` for both training and search, see this [test](../../tests/train_eval_blocks_test.py). This notebook only contains the training part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pymimir\n",
    "import wlplan\n",
    "import time\n",
    "from wlplan.data import Dataset, ProblemStates\n",
    "from wlplan.feature_generation import get_feature_generator\n",
    "from wlplan.planning import State, parse_domain, parse_problem\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [The most work] Parse the PDDL domain and training data in the form of (state, optimal cost to go) pairs using a parser of your choice. Here, I used `mimir` but anything else can do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:04<00:00, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to parse data: 4.43 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "\n",
    "# Initialise WLPlan domain\n",
    "DOMAIN_PDDL = \"blocksworld/domain.pddl\"\n",
    "wlplan_domain = parse_domain(DOMAIN_PDDL)\n",
    "predicates = wlplan_domain.predicates\n",
    "name_to_predicate = {p.name: p for p in predicates}\n",
    "\n",
    "wlplan_data = []\n",
    "y = []\n",
    "\n",
    "# Construct dataset\n",
    "mimir_domain = pymimir.DomainParser(str(DOMAIN_PDDL)).parse()\n",
    "for f in tqdm(sorted(os.listdir(\"blocksworld/training_plans\"))):\n",
    "    PROBLEM_PDDL = \"blocksworld/training/\" + f.replace(\".plan\", \".pddl\")\n",
    "\n",
    "    # Initialise WLPlan problem\n",
    "    wlplan_problem = parse_problem(DOMAIN_PDDL, PROBLEM_PDDL)\n",
    "    \n",
    "    # Parse problem and plan with mimir\n",
    "    plan_file = \"blocksworld/training_plans/\" + f\n",
    "    mimir_problem = pymimir.ProblemParser(str(PROBLEM_PDDL)).parse(mimir_domain)\n",
    "    mimir_state = mimir_problem.create_state(mimir_problem.initial)\n",
    "\n",
    "    name_to_schema = {s.name: s for s in mimir_domain.action_schemas}\n",
    "    name_to_object = {o.name: o for o in mimir_problem.objects}\n",
    "    \n",
    "    # Collect actions\n",
    "    actions = []\n",
    "    with open(plan_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith(\";\"):\n",
    "                continue\n",
    "            action_name = line.strip()\n",
    "            action_name = action_name.replace(\"(\", \"\")\n",
    "            action_name = action_name.replace(\")\", \"\")\n",
    "            toks = action_name.split(\" \")\n",
    "            schema = toks[0]\n",
    "            schema = name_to_schema[schema]\n",
    "            args = toks[1:]\n",
    "            args = [name_to_object[arg] for arg in args]\n",
    "            action = pymimir.Action.new(mimir_problem, schema, args)\n",
    "            actions.append(action)\n",
    "\n",
    "    # Collect plan trace states\n",
    "    wlplan_states = []\n",
    "\n",
    "    def mimir_to_wlplan_state(mimir_state: pymimir.State):\n",
    "        atoms = []\n",
    "        for atom in mimir_state.get_atoms():\n",
    "            wlplan_atom = wlplan.planning.Atom(\n",
    "                predicate=name_to_predicate[atom.predicate.name],\n",
    "                objects=[o.name for o in atom.terms],\n",
    "            )\n",
    "            atoms.append(wlplan_atom)\n",
    "        return State(atoms)\n",
    "    \n",
    "    h_opt = len(actions)\n",
    "    wlplan_states.append(mimir_to_wlplan_state(mimir_state))\n",
    "    y.append(h_opt)\n",
    "    for action in actions:\n",
    "        h_opt -= 1\n",
    "        mimir_state = action.apply(mimir_state)\n",
    "        wlplan_states.append(mimir_to_wlplan_state(mimir_state))\n",
    "        y.append(h_opt)\n",
    "\n",
    "    problem_states = ProblemStates(problem=wlplan_problem, states=wlplan_states)\n",
    "    wlplan_data.append(problem_states)\n",
    "\n",
    "# This is what we need to feed into our feature generator below\n",
    "dataset = Dataset(domain=wlplan_domain, data=wlplan_data)\n",
    "\n",
    "t = time.time() - t\n",
    "print(f\"Time taken to parse data: {t:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Collect and generate features from the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WLPLAN_CONFIG = {\n",
    "    \"domain\": wlplan_domain,\n",
    "    \"iterations\": 4,\n",
    "    \"feature_algorithm\": \"wl\",\n",
    "    \"graph_representation\": \"ilg\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0]\n",
      "Collecting.\n",
      "[Iteration 1]\n",
      "Collecting.\n",
      "[Iteration 2]\n",
      "Collecting.\n",
      "[Iteration 3]\n",
      "Collecting.\n",
      "[Iteration 4]\n",
      "Collecting.\n",
      "[complete]\n",
      "X.shape=(1348, 10445)\n",
      "y.shape=(1348,)\n",
      "Feature generation took 0.82 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "feature_generator = get_feature_generator(**WLPLAN_CONFIG)\n",
    "feature_generator.collect(dataset)\n",
    "X = np.array(feature_generator.embed(dataset)).astype(float)\n",
    "y = np.array(y)\n",
    "\n",
    "t = time.time() - t\n",
    "\n",
    "print(f\"{X.shape=}\")\n",
    "print(f\"{y.shape=}\")\n",
    "print(f\"Feature generation took {t:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train a Gaussian Process Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=1.0568576234132687e-17\n",
      "Training and prediction took 1.29 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "linear_kernel = DotProduct(sigma_0=0, sigma_0_bounds=\"fixed\")\n",
    "model = GaussianProcessRegressor(kernel=linear_kernel, alpha=1e-7, random_state=0)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "loss = np.mean((y - y_pred) ** 2)\n",
    "\n",
    "t = time.time() - t\n",
    "\n",
    "print(f\"{loss=}\")\n",
    "print(f\"Training and prediction took {t:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wlplan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
